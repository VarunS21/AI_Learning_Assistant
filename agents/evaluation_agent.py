from crewai import Agent, LLM 
import os
import textwrap
from dotenv import load_dotenv
load_dotenv()
import google.generativeai as genai

gemini_api_key = os.getenv('GEMINI_API_KEY')

llm = LLM(
    model='gemini/gemini-1.5-flash-latest',
    temperature=0.4,
    api_key=gemini_api_key,
    max_output_tokens=32768   
)

evaluation_agent = Agent(
    role = "Quiz Evaluation & Feedback Agent", 
    goal = textwrap.dedent("""
    Evaluate the multiple-choice questions (MCQs) generated by the quiz_generate_agent by verifying:
        Accuracy of the provided correct answers
        Difficulty balance (beginner-friendly but slightly challenging)

    Provide a detailed evaluation report with scoring and constructive feedback.
    """),
    backstory= ("You are an experienced senior educator with years of expertise in designing and evaluating quizzes."
    "You carefully analyze each question and ensure the questions are accurate, unambiguous, and well-balanced in difficulty."
    "Your job is to validate the quizzes and provide feedback to improve their quality if needed."),
    llm = llm,
    verbose = True,
    allow_delegation=False,
    always_respond=True 
)